{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_file = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# load doc list\n",
    "with open('doc_list.txt') as f:\n",
    "    doc_list = f.read().splitlines()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 14955/14955 [00:51<00:00, 288.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# load doc from list\n",
    "if ~load_from_file:\n",
    "  docs_counter = []\n",
    "  words = set()\n",
    "  for doc in tqdm(doc_list):\n",
    "      with open('docs/' + doc + '.txt') as f:\n",
    "          doc_words = f.read().split()\n",
    "          docs_counter.append(Counter(doc_words))\n",
    "          words = words.union(set(doc_words))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load query list\n",
    "with open('query_list.txt') as f:\n",
    "    query_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4364.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# load query from list\n",
    "queries = []\n",
    "queries_words = set()\n",
    "for query in tqdm(query_list):\n",
    "    with open('queries/' + query + '.txt') as f:\n",
    "        query_words = f.read().split()\n",
    "        queries.append(query_words)\n",
    "        if load_from_file == False:\n",
    "            words = words.union(set(query_words))\n",
    "            queries_words = queries_words.union(set(query_words))\n",
    "\n",
    "if load_from_file:\n",
    "    # load query words from file\n",
    "    with open('query_word_list.txt') as f:\n",
    "        queries_words = f.read().split()\n",
    "else:\n",
    "    # save query words\n",
    "    with open('query_word_list.txt', 'w') as f:\n",
    "        f.write(' '.join(queries_words))\n",
    "    \n",
    "    queries_words = list(queries_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_file:\n",
    "    # load words dict from file\n",
    "    with open('word_list.txt') as f:\n",
    "        words = f.read().split()\n",
    "else:\n",
    "    # save words\n",
    "    with open('word_list.txt', 'w') as f:\n",
    "        f.write(' '.join(words))\n",
    "\n",
    "    words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14955 111449 226\n"
     ]
    }
   ],
   "source": [
    "docs_amount = len(doc_list)\n",
    "words_amount = len(words)\n",
    "query_word_amount = len(queries_words)\n",
    "\n",
    "print(docs_amount, words_amount, query_word_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document length\n",
    "if load_from_file:\n",
    "    docs_len = np.load('docs_len.npy')\n",
    "else:\n",
    "    docs_len = []\n",
    "\n",
    "    for j in tqdm(range(docs_amount)):\n",
    "        docs_len.append(sum(docs_counter[j].values()))\n",
    "\n",
    "    docs_len = np.array(docs_len)\n",
    "    np.save('docs_len', docs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 14955/14955 [10:29<00:00, 23.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# all words count in documents and probability\n",
    "if load_from_file:\n",
    "    cwd = scipy.sparse.load_npz('cwd.npz')\n",
    "    pwd = scipy.sparse.load_npz('pwd.npz')\n",
    "else:\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    cwd_data = []\n",
    "    pwd_data = []\n",
    "\n",
    "    for j in tqdm(range(docs_amount)):\n",
    "        doc_len = docs_len[j]\n",
    "\n",
    "        for i in range(words_amount):\n",
    "            word_count = docs_counter[j][words[i]]\n",
    "            if word_count != 0:\n",
    "                indices.append(i)\n",
    "                cwd_data.append(word_count)\n",
    "                pwd_data.append(word_count / doc_len)\n",
    "        indptr.append(len(indices))\n",
    "\n",
    "    cwd = scipy.sparse.csr_matrix((cwd_data, indices, indptr), dtype=np.float32).transpose()\n",
    "    pwd = scipy.sparse.csr_matrix((pwd_data, indices, indptr), dtype=np.float32).transpose()\n",
    "\n",
    "    scipy.sparse.save_npz('cwd', cwd)\n",
    "    scipy.sparse.save_npz('pwd', pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "111449it [00:11, 9962.48it/s]\n",
      "10208\n"
     ]
    }
   ],
   "source": [
    "# process slim words\n",
    "if load_from_file:\n",
    "    with open('slim_word_list.txt') as f:\n",
    "        slim_words = f.read().split()\n",
    "else:\n",
    "    words_count_list = []\n",
    "    for word_row in tqdm(cwd):\n",
    "        words_count_list.append(word_row.sum())\n",
    "        \n",
    "    most_word_index = np.flip(np.argsort(words_count_list))\n",
    "\n",
    "    slim_words_amount = 10000\n",
    "    slim_words = []\n",
    "    for word_index in range(slim_words_amount):\n",
    "        slim_words.append(words[word_index])\n",
    "    \n",
    "    slim_words = slim_words + queries_words\n",
    "    slim_words = list(set(slim_words))\n",
    "\n",
    "    # save slim words\n",
    "    with open('slim_word_list.txt', 'w') as f:\n",
    "        f.write(' '.join(slim_words))\n",
    "\n",
    "# update slim words amount\n",
    "slim_words_amount = len(slim_words)\n",
    "print(slim_words_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 14955/14955 [00:59<00:00, 251.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# slim words count in documents and probability\n",
    "if load_from_file:\n",
    "    slim_cwd = scipy.sparse.load_npz('slim_cwd.npz').A\n",
    "    slim_pwd = scipy.sparse.load_npz('slim_pwd.npz').A\n",
    "else:\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    cwd_data = []\n",
    "    pwd_data = []\n",
    "\n",
    "    for j in tqdm(range(docs_amount)):\n",
    "        doc_len = docs_len[j]\n",
    "        for i in range(slim_words_amount):\n",
    "            word_count = docs_counter[j][slim_words[i]]\n",
    "            if word_count != 0:\n",
    "                indices.append(i)\n",
    "                cwd_data.append(word_count)\n",
    "                pwd_data.append(word_count / doc_len)\n",
    "        indptr.append(len(indices))\n",
    "\n",
    "    slim_cwd = scipy.sparse.csr_matrix((cwd_data, indices, indptr), dtype=np.float32).transpose()\n",
    "    slim_pwd = scipy.sparse.csr_matrix((pwd_data, indices, indptr), dtype=np.float32).transpose()\n",
    "\n",
    "    scipy.sparse.save_npz('slim_cwd', slim_cwd)\n",
    "    scipy.sparse.save_npz('slim_pwd', slim_pwd)\n",
    "\n",
    "    slim_cwd = slim_cwd.A\n",
    "    slim_pwd = slim_pwd.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 10208/10208 [00:01<00:00, 7198.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# background language model\n",
    "bg = []\n",
    "bg_model_cd = docs_len.sum()\n",
    "\n",
    "for word_row in tqdm(slim_cwd):\n",
    "    bg.append(word_row.sum() / bg_model_cd)\n",
    "\n",
    "bg = np.array(bg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def E_step():\n",
    "#     ptwd_CD = np.matmul(pwt, ptd) # Common Denominator\n",
    "#     for i in range(slim_words_amount):\n",
    "#         for j in range(docs_amount):\n",
    "#             if ptwd_CD[i][j] != 0:\n",
    "#                 for k in range(topic_k):\n",
    "#                     ptwd[k][i][j] = pwt[i][k] * ptd[k][j] / ptwd_CD[i][j]\n",
    "#             else:\n",
    "#                 ptwd[:,i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def nb_E_step(pwt, ptd, cwd, topic_amount, word_amount, doc_amount):\n",
    "    # empty matrix\n",
    "    ptwd = np.empty((topic_amount, word_amount, doc_amount))\n",
    "\n",
    "    # Common Denominator\n",
    "    # ptwd_CD = np.dot(pwt, ptd) \n",
    "\n",
    "    for i in range(word_amount):\n",
    "        for j in range(doc_amount):\n",
    "            if cwd[i][j] != 0: \n",
    "                ptwd_CD = 0\n",
    "                for k in range(topic_amount):\n",
    "                    single_ptwd = pwt[i][k] * ptd[k][j]\n",
    "                    ptwd[k][i][j] = single_ptwd\n",
    "                    ptwd_CD += single_ptwd\n",
    "                if ptwd_CD != 0:\n",
    "                    for k in range(topic_amount):\n",
    "                        ptwd[k][i][j] /= ptwd_CD\n",
    "                else:\n",
    "                    ptwd[:,i,j] = 0\n",
    "            else:\n",
    "                ptwd[:,i,j] = 0\n",
    "    return ptwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @jit\n",
    "# def M_step():\n",
    "#     # p(w/t)\n",
    "#     for k in range(topic_k):\n",
    "#         single_wt = np.multiply(cwd, ptwd[k])\n",
    "#         single_wt_sum = single_wt.sum()\n",
    "#         if single_wt_sum != 0:\n",
    "#             for i in range(len(words)):\n",
    "#                 pwt[i][k] = single_wt[i].sum() / single_wt_sum\n",
    "#         else:\n",
    "#             for i in range(len(words)):\n",
    "#                 pwt[i][k] = 0\n",
    "    \n",
    "#     for i in range(len(pwt)):\n",
    "#         pwt[i] /= pwt[i].sum()\n",
    "\n",
    "#     # p(t/d)\n",
    "#     for k in range(topic_k):\n",
    "#         single_k_cwd_ptwd = np.multiply(cwd, ptwd[k])\n",
    "#         for j in range(len(docs)):\n",
    "#             if docs_len[j] != 0:\n",
    "#                 ptd[k][j] = single_k_cwd_ptwd[:,j].sum() / docs_len[j]\n",
    "#             else:\n",
    "#                 ptd[k][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit\n",
    "def M_step(times):\n",
    "    for k in range(topic_k):\n",
    "        single_topic_wd = np.multiply(cwd, ptwd[k])\n",
    "\n",
    "        # p(w/t)\n",
    "        single_wt_sum = single_topic_wd.sum()\n",
    "        if single_wt_sum != 0:\n",
    "            for i in range(slim_words_amount):\n",
    "                pwt[i][k] = single_topic_wd[i].sum() / single_wt_sum\n",
    "        else:\n",
    "            pwt[:,k] = 1 / slim_words_amount\n",
    "\n",
    "        # p(t/d)\n",
    "        for j in range(docs_amount):\n",
    "            ptd[k][j] = single_topic_wd[:,j].sum() / docs_len[j]\n",
    "    \n",
    "    # # norm to 1\n",
    "    # for k in range(topic_k):\n",
    "    #     if np.isnan(pwt[:,k].sum()):\n",
    "    #         print(times, \"norm \", k)\n",
    "    #     pwt[:,k] /= pwt[:,k].sum()\n",
    "    for j in range(docs_amount):\n",
    "        deno = ptd[:,j].sum()\n",
    "        if deno != 0:\n",
    "            ptd[:,j] /= deno\n",
    "        else:\n",
    "            ptd[:,j].fill(1 / topic_k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def nb_M_step(ptwd, cwd, docs_len, topic_amount, word_amount, doc_amount):\n",
    "    # empty matrix\n",
    "    pwt = np.empty((word_amount, topic_amount))\n",
    "    ptd = np.empty((topic_amount, doc_amount))\n",
    "\n",
    "    for k in range(topic_amount):\n",
    "        single_topic_wd = np.multiply(cwd, ptwd[k])\n",
    "\n",
    "        # p(w/t)\n",
    "        single_wt_sum = single_topic_wd.sum()\n",
    "        if single_wt_sum != 0:\n",
    "            for i in range(word_amount):\n",
    "                pwt[i][k] = single_topic_wd[i].sum() / single_wt_sum\n",
    "        else:\n",
    "            pwt[:,k] = 1 / slim_words_amount\n",
    "\n",
    "        # p(t/d)\n",
    "        for j in range(doc_amount):\n",
    "            ptd[k][j] = single_topic_wd[:,j].sum() / docs_len[j]\n",
    "    \n",
    "    # # norm to 1\n",
    "    # for k in range(topic_k):\n",
    "    #     if np.isnan(pwt[:,k].sum()):\n",
    "    #         print(times, \"norm \", k)\n",
    "    #     pwt[:,k] /= pwt[:,k].sum()\n",
    "    for j in range(doc_amount):\n",
    "        deno = ptd[:,j].sum()\n",
    "        if deno != 0:\n",
    "            ptd[:,j] /= deno\n",
    "        else:\n",
    "            ptd[:,j].fill(1 / topic_amount) \n",
    "    \n",
    "    return pwt, ptd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(times):\n",
    "    loss = np.multiply(cwd, np.log(np.matmul(pwt, ptd))).sum()\n",
    "    print(\"\\nStep\", times, \"loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def nb_loss(times, cwd, pwt, ptd):\n",
    "    loss = np.multiply(cwd, np.log(np.dot(pwt, ptd))).sum()\n",
    "    print(\"\\nStep\", times, \"loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic\n",
    "\n",
    "topic_k = 32\n",
    "EPOCH = 50\n",
    "alpha = 0.6\n",
    "beta = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EM Step Initial (normal)\n",
    "pwt = np.random.random(size = (slim_words_amount, topic_k))\n",
    "\n",
    "for k in range(topic_k):\n",
    "    pwt[:,k] /= pwt[:,k].sum()\n",
    "\n",
    "ptd = np.full((topic_k, docs_amount), 1 / topic_k)\n",
    "\n",
    "ptwd = np.empty((topic_k, slim_words_amount, docs_amount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 20/20 [1:07:43<00:00, 203.20s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(EPOCH)):\n",
    "    # nb_E_step(pwt, ptd, cwd, topic_amount, word_amount, doc_amount)\n",
    "    ptwd = nb_E_step(pwt, ptd, slim_cwd, topic_k, slim_words_amount, docs_amount)\n",
    "    # nb_M_step(ptwd, cwd, docs_len, topic_amount, word_amount, doc_amount)\n",
    "    pwt, ptd = nb_M_step(ptwd, slim_cwd, docs_len, topic_k, slim_words_amount, docs_amount)\n",
    "    # nb_loss(times, cwd, pwt, ptd)\n",
    "    # nb_loss(i + 1, slim_cwd, pwt, ptd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsa_EM_final = np.matmul(pwt, ptd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10208, 14955)"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "source": [
    "plsa_EM_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 100/100 [05:45<00:00,  3.45s/it]\n"
     ]
    }
   ],
   "source": [
    "queries_result = []\n",
    "\n",
    "for query in tqdm(queries):\n",
    "    query_result = []\n",
    "    for doc_index in range(docs_amount):\n",
    "        plsa_result = 1\n",
    "        for word in query:\n",
    "            word_index = slim_words.index(word)\n",
    "            unigram_pwd = slim_pwd[word_index][doc_index]\n",
    "            plsa_result = plsa_result * (alpha * unigram_pwd + beta * plsa_EM_final[word_index][doc_index] + (1 - alpha - beta) * bg[word_index])\n",
    "            \n",
    "            # plsa_result = plsa_result * (alpha * unigram_pwd + (1 - alpha - beta) * bg[word_index])\n",
    "        query_result.append(plsa_result)\n",
    "    queries_result.append(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort and export result\n",
    "sim_df = pd.DataFrame(queries_result)\n",
    "sim_df = sim_df.transpose()\n",
    "sim_df.index = doc_list\n",
    "sim_df.columns = query_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        301           302           303           304  \\\n",
       "FBIS3-1001     7.844099e-09  7.849734e-16  1.274814e-15  3.106111e-09   \n",
       "FBIS3-10014    3.297196e-10  1.283606e-15  4.899966e-13  1.019672e-14   \n",
       "FBIS3-10035    5.797906e-09  4.765186e-12  2.694060e-12  1.571261e-14   \n",
       "FBIS3-1007     5.566566e-09  1.601474e-13  7.229363e-16  9.946346e-15   \n",
       "FBIS3-10082    1.344726e-08  2.077823e-15  1.442651e-15  9.946419e-15   \n",
       "...                     ...           ...           ...           ...   \n",
       "LA123190-0062  1.155658e-09  2.213033e-15  4.999048e-15  2.390150e-10   \n",
       "LA123190-0065  2.955998e-10  8.496913e-15  5.232009e-16  9.946078e-15   \n",
       "LA123190-0069  1.818882e-11  1.134254e-15  5.869964e-16  1.003980e-14   \n",
       "LA123190-0089  2.116689e-10  9.811996e-16  7.381630e-16  9.946079e-15   \n",
       "LA123190-0117  4.317664e-11  1.907547e-13  4.976269e-16  9.946079e-15   \n",
       "\n",
       "                        305           306           307           308  \\\n",
       "FBIS3-1001     7.052925e-08  2.063657e-11  1.185478e-11  2.879457e-12   \n",
       "FBIS3-10014    8.877052e-08  9.617417e-12  2.439827e-11  7.079869e-12   \n",
       "FBIS3-10035    5.635946e-08  1.330651e-12  4.351448e-11  4.781515e-09   \n",
       "FBIS3-1007     2.894528e-08  8.093462e-11  3.850425e-11  2.771099e-10   \n",
       "FBIS3-10082    3.632382e-08  3.084406e-12  1.356564e-11  2.895015e-12   \n",
       "...                     ...           ...           ...           ...   \n",
       "LA123190-0062  5.537168e-08  8.670230e-09  1.293670e-10  3.662383e-12   \n",
       "LA123190-0065  4.554302e-08  2.207681e-10  1.143272e-11  2.879954e-12   \n",
       "LA123190-0069  7.457401e-08  1.608521e-11  9.436688e-12  9.551267e-10   \n",
       "LA123190-0089  2.775759e-08  6.707682e-13  9.382999e-08  7.447472e-11   \n",
       "LA123190-0117  1.127203e-07  5.256331e-09  1.668081e-09  1.999511e-09   \n",
       "\n",
       "                        309           310  ...           391       392  \\\n",
       "FBIS3-1001     2.755302e-09  1.977412e-18  ...  9.075182e-08  0.000026   \n",
       "FBIS3-10014    1.215097e-09  5.179315e-17  ...  9.075182e-08  0.000026   \n",
       "FBIS3-10035    2.453849e-09  5.070105e-14  ...  1.075632e-07  0.000026   \n",
       "FBIS3-1007     6.058272e-09  1.074080e-15  ...  3.724922e-06  0.000026   \n",
       "FBIS3-10082    3.495033e-08  1.388209e-17  ...  5.764371e-06  0.000026   \n",
       "...                     ...           ...  ...           ...       ...   \n",
       "LA123190-0062  7.882543e-09  1.515021e-17  ...  2.626347e-07  0.000026   \n",
       "LA123190-0065  3.806054e-08  1.526408e-17  ...  2.505451e-06  0.000026   \n",
       "LA123190-0069  4.095120e-09  2.850526e-17  ...  9.076959e-08  0.000026   \n",
       "LA123190-0089  2.736146e-09  1.787428e-17  ...  9.084109e-08  0.000026   \n",
       "LA123190-0117  3.205562e-09  1.178648e-14  ...  9.075233e-08  0.000026   \n",
       "\n",
       "                        393           394       395           396  \\\n",
       "FBIS3-1001     3.095598e-09  3.459057e-08  0.000036  2.231322e-14   \n",
       "FBIS3-10014    2.493364e-09  1.006079e-06  0.000036  5.369635e-14   \n",
       "FBIS3-10035    1.953508e-09  6.252042e-07  0.001147  9.522312e-11   \n",
       "FBIS3-1007     3.475826e-09  4.957312e-08  0.000036  2.918694e-12   \n",
       "FBIS3-10082    1.999834e-08  1.180914e-07  0.000886  1.993157e-13   \n",
       "...                     ...           ...       ...           ...   \n",
       "LA123190-0062  1.690260e-08  3.054801e-07  0.000234  2.461188e-13   \n",
       "LA123190-0065  1.299618e-06  1.621377e-07  0.000036  7.005154e-14   \n",
       "LA123190-0069  1.133633e-07  1.082940e-06  0.000036  1.171648e-11   \n",
       "LA123190-0089  2.858647e-09  2.269726e-07  0.000036  1.517991e-12   \n",
       "LA123190-0117  1.647925e-06  1.411547e-06  0.000036  2.050963e-11   \n",
       "\n",
       "                        397           398           399           400  \n",
       "FBIS3-1001     1.440622e-09  3.589058e-14  1.373540e-07  1.066275e-14  \n",
       "FBIS3-10014    3.489751e-09  5.728465e-12  4.802940e-10  1.066257e-14  \n",
       "FBIS3-10035    3.667022e-09  1.873587e-12  9.243940e-11  3.567190e-11  \n",
       "FBIS3-1007     5.914333e-09  5.948465e-13  9.237538e-11  1.066257e-14  \n",
       "FBIS3-10082    1.585943e-08  2.865337e-13  9.238008e-11  1.066257e-14  \n",
       "...                     ...           ...           ...           ...  \n",
       "LA123190-0062  2.443372e-08  4.620844e-13  2.885301e-08  1.113715e-14  \n",
       "LA123190-0065  1.921439e-08  2.082375e-13  9.238721e-11  1.106068e-14  \n",
       "LA123190-0069  2.285321e-08  1.227615e-13  2.374386e-10  1.125836e-14  \n",
       "LA123190-0089  1.315771e-08  3.309848e-14  9.239268e-11  1.122154e-14  \n",
       "LA123190-0117  6.049732e-08  1.180946e-14  9.242670e-11  1.222983e-14  \n",
       "\n",
       "[14955 rows x 100 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>301</th>\n      <th>302</th>\n      <th>303</th>\n      <th>304</th>\n      <th>305</th>\n      <th>306</th>\n      <th>307</th>\n      <th>308</th>\n      <th>309</th>\n      <th>310</th>\n      <th>...</th>\n      <th>391</th>\n      <th>392</th>\n      <th>393</th>\n      <th>394</th>\n      <th>395</th>\n      <th>396</th>\n      <th>397</th>\n      <th>398</th>\n      <th>399</th>\n      <th>400</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>FBIS3-1001</th>\n      <td>7.844099e-09</td>\n      <td>7.849734e-16</td>\n      <td>1.274814e-15</td>\n      <td>3.106111e-09</td>\n      <td>7.052925e-08</td>\n      <td>2.063657e-11</td>\n      <td>1.185478e-11</td>\n      <td>2.879457e-12</td>\n      <td>2.755302e-09</td>\n      <td>1.977412e-18</td>\n      <td>...</td>\n      <td>9.075182e-08</td>\n      <td>0.000026</td>\n      <td>3.095598e-09</td>\n      <td>3.459057e-08</td>\n      <td>0.000036</td>\n      <td>2.231322e-14</td>\n      <td>1.440622e-09</td>\n      <td>3.589058e-14</td>\n      <td>1.373540e-07</td>\n      <td>1.066275e-14</td>\n    </tr>\n    <tr>\n      <th>FBIS3-10014</th>\n      <td>3.297196e-10</td>\n      <td>1.283606e-15</td>\n      <td>4.899966e-13</td>\n      <td>1.019672e-14</td>\n      <td>8.877052e-08</td>\n      <td>9.617417e-12</td>\n      <td>2.439827e-11</td>\n      <td>7.079869e-12</td>\n      <td>1.215097e-09</td>\n      <td>5.179315e-17</td>\n      <td>...</td>\n      <td>9.075182e-08</td>\n      <td>0.000026</td>\n      <td>2.493364e-09</td>\n      <td>1.006079e-06</td>\n      <td>0.000036</td>\n      <td>5.369635e-14</td>\n      <td>3.489751e-09</td>\n      <td>5.728465e-12</td>\n      <td>4.802940e-10</td>\n      <td>1.066257e-14</td>\n    </tr>\n    <tr>\n      <th>FBIS3-10035</th>\n      <td>5.797906e-09</td>\n      <td>4.765186e-12</td>\n      <td>2.694060e-12</td>\n      <td>1.571261e-14</td>\n      <td>5.635946e-08</td>\n      <td>1.330651e-12</td>\n      <td>4.351448e-11</td>\n      <td>4.781515e-09</td>\n      <td>2.453849e-09</td>\n      <td>5.070105e-14</td>\n      <td>...</td>\n      <td>1.075632e-07</td>\n      <td>0.000026</td>\n      <td>1.953508e-09</td>\n      <td>6.252042e-07</td>\n      <td>0.001147</td>\n      <td>9.522312e-11</td>\n      <td>3.667022e-09</td>\n      <td>1.873587e-12</td>\n      <td>9.243940e-11</td>\n      <td>3.567190e-11</td>\n    </tr>\n    <tr>\n      <th>FBIS3-1007</th>\n      <td>5.566566e-09</td>\n      <td>1.601474e-13</td>\n      <td>7.229363e-16</td>\n      <td>9.946346e-15</td>\n      <td>2.894528e-08</td>\n      <td>8.093462e-11</td>\n      <td>3.850425e-11</td>\n      <td>2.771099e-10</td>\n      <td>6.058272e-09</td>\n      <td>1.074080e-15</td>\n      <td>...</td>\n      <td>3.724922e-06</td>\n      <td>0.000026</td>\n      <td>3.475826e-09</td>\n      <td>4.957312e-08</td>\n      <td>0.000036</td>\n      <td>2.918694e-12</td>\n      <td>5.914333e-09</td>\n      <td>5.948465e-13</td>\n      <td>9.237538e-11</td>\n      <td>1.066257e-14</td>\n    </tr>\n    <tr>\n      <th>FBIS3-10082</th>\n      <td>1.344726e-08</td>\n      <td>2.077823e-15</td>\n      <td>1.442651e-15</td>\n      <td>9.946419e-15</td>\n      <td>3.632382e-08</td>\n      <td>3.084406e-12</td>\n      <td>1.356564e-11</td>\n      <td>2.895015e-12</td>\n      <td>3.495033e-08</td>\n      <td>1.388209e-17</td>\n      <td>...</td>\n      <td>5.764371e-06</td>\n      <td>0.000026</td>\n      <td>1.999834e-08</td>\n      <td>1.180914e-07</td>\n      <td>0.000886</td>\n      <td>1.993157e-13</td>\n      <td>1.585943e-08</td>\n      <td>2.865337e-13</td>\n      <td>9.238008e-11</td>\n      <td>1.066257e-14</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>LA123190-0062</th>\n      <td>1.155658e-09</td>\n      <td>2.213033e-15</td>\n      <td>4.999048e-15</td>\n      <td>2.390150e-10</td>\n      <td>5.537168e-08</td>\n      <td>8.670230e-09</td>\n      <td>1.293670e-10</td>\n      <td>3.662383e-12</td>\n      <td>7.882543e-09</td>\n      <td>1.515021e-17</td>\n      <td>...</td>\n      <td>2.626347e-07</td>\n      <td>0.000026</td>\n      <td>1.690260e-08</td>\n      <td>3.054801e-07</td>\n      <td>0.000234</td>\n      <td>2.461188e-13</td>\n      <td>2.443372e-08</td>\n      <td>4.620844e-13</td>\n      <td>2.885301e-08</td>\n      <td>1.113715e-14</td>\n    </tr>\n    <tr>\n      <th>LA123190-0065</th>\n      <td>2.955998e-10</td>\n      <td>8.496913e-15</td>\n      <td>5.232009e-16</td>\n      <td>9.946078e-15</td>\n      <td>4.554302e-08</td>\n      <td>2.207681e-10</td>\n      <td>1.143272e-11</td>\n      <td>2.879954e-12</td>\n      <td>3.806054e-08</td>\n      <td>1.526408e-17</td>\n      <td>...</td>\n      <td>2.505451e-06</td>\n      <td>0.000026</td>\n      <td>1.299618e-06</td>\n      <td>1.621377e-07</td>\n      <td>0.000036</td>\n      <td>7.005154e-14</td>\n      <td>1.921439e-08</td>\n      <td>2.082375e-13</td>\n      <td>9.238721e-11</td>\n      <td>1.106068e-14</td>\n    </tr>\n    <tr>\n      <th>LA123190-0069</th>\n      <td>1.818882e-11</td>\n      <td>1.134254e-15</td>\n      <td>5.869964e-16</td>\n      <td>1.003980e-14</td>\n      <td>7.457401e-08</td>\n      <td>1.608521e-11</td>\n      <td>9.436688e-12</td>\n      <td>9.551267e-10</td>\n      <td>4.095120e-09</td>\n      <td>2.850526e-17</td>\n      <td>...</td>\n      <td>9.076959e-08</td>\n      <td>0.000026</td>\n      <td>1.133633e-07</td>\n      <td>1.082940e-06</td>\n      <td>0.000036</td>\n      <td>1.171648e-11</td>\n      <td>2.285321e-08</td>\n      <td>1.227615e-13</td>\n      <td>2.374386e-10</td>\n      <td>1.125836e-14</td>\n    </tr>\n    <tr>\n      <th>LA123190-0089</th>\n      <td>2.116689e-10</td>\n      <td>9.811996e-16</td>\n      <td>7.381630e-16</td>\n      <td>9.946079e-15</td>\n      <td>2.775759e-08</td>\n      <td>6.707682e-13</td>\n      <td>9.382999e-08</td>\n      <td>7.447472e-11</td>\n      <td>2.736146e-09</td>\n      <td>1.787428e-17</td>\n      <td>...</td>\n      <td>9.084109e-08</td>\n      <td>0.000026</td>\n      <td>2.858647e-09</td>\n      <td>2.269726e-07</td>\n      <td>0.000036</td>\n      <td>1.517991e-12</td>\n      <td>1.315771e-08</td>\n      <td>3.309848e-14</td>\n      <td>9.239268e-11</td>\n      <td>1.122154e-14</td>\n    </tr>\n    <tr>\n      <th>LA123190-0117</th>\n      <td>4.317664e-11</td>\n      <td>1.907547e-13</td>\n      <td>4.976269e-16</td>\n      <td>9.946079e-15</td>\n      <td>1.127203e-07</td>\n      <td>5.256331e-09</td>\n      <td>1.668081e-09</td>\n      <td>1.999511e-09</td>\n      <td>3.205562e-09</td>\n      <td>1.178648e-14</td>\n      <td>...</td>\n      <td>9.075233e-08</td>\n      <td>0.000026</td>\n      <td>1.647925e-06</td>\n      <td>1.411547e-06</td>\n      <td>0.000036</td>\n      <td>2.050963e-11</td>\n      <td>6.049732e-08</td>\n      <td>1.180946e-14</td>\n      <td>9.242670e-11</td>\n      <td>1.222983e-14</td>\n    </tr>\n  </tbody>\n</table>\n<p>14955 rows × 100 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "results/result_topic32_EPOCH50_a0.6_b0.2_201124_1603.txt\n"
     ]
    }
   ],
   "source": [
    "# save results\n",
    "now = datetime.datetime.now()\n",
    "save_filename = 'results/result' + '_' + 'topic' + str(topic_k) + '_EPOCH' + str(EPOCH) + '_a' + str(alpha) + '_b' + str(beta) + now.strftime(\"_%y%m%d_%H%M\") + '.txt'\n",
    "print(save_filename)\n",
    "\n",
    "with open(save_filename, 'w') as f:\n",
    "    f.write('Query,RetrievedDocuments\\n')\n",
    "    for query in query_list:\n",
    "        f.write(query + \",\")\n",
    "        query_sim_df = sim_df[query].sort_values(ascending=False)\n",
    "        f.write(' '.join(query_sim_df[:1000].index.to_list()) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_pwt = scipy.sparse.csr_matrix(pwt)\n",
    "sparse_ptd = scipy.sparse.csr_matrix(ptd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.sparse.save_npz('sparse_pwt' + '_' + 'topic' + str(topic_k) + '_EPOCH' + str(EPOCH), sparse_pwt)\n",
    "scipy.sparse.save_npz('sparse_ptd' + '_' + 'topic' + str(topic_k) + '_EPOCH' + str(EPOCH), sparse_ptd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0\n1.0\n1.0000000000000004\n1.0\n1.0\n0.9999999999999999\n0.9999999999999999\n1.0\n0.9999999999999999\n1.0\n0.9999999999999998\n0.9999999999999999\n0.9999999999999998\n0.9999999999999997\n1.0\n1.0\n1.0000000000000002\n1.0\n1.0\n1.0\n1.0000000000000002\n1.0\n1.0\n1.0\n1.0000000000000002\n1.0\n1.0\n1.0\n1.0000000000000002\n1.0\n1.0\n1.0\n1.0\n1.0\n1.0\n0.9999999999999999\n0.9999999999999999\n1.0\n1.0\n0.9999999999999999\n1.0000000000000002\n0.9999999999999999\n1.0\n1.0\n1.0\n1.0000000000000002\n1.0000000000000002\n1.0\n1.0000000000000002\n1.0\n1.0000000000000004\n1.0\n1.0\n1.0000000000000002\n1.0\n1.0000000000000002\n1.0\n0.9999999999999999\n1.0\n1.0000000000000002\n1.0\n1.0000000000000002\n0.9999999999999999\n0.9999999999999999\n1.0000000000000002\n1.0\n0.9999999999999999\n0.9999999999999999\n1.0000000000000002\n1.0000000000000004\n0.9999999999999998\n0.9999999999999999\n1.0\n0.9999999999999998\n1.0000000000000002\n1.0\n0.9999999999999998\n1.0\n1.0\n0.9999999999999999\n1.0\n1.0000000000000002\n0.9999999999999999\n0.9999999999999993\n1.0\n0.9999999999999998\n1.0\n1.0\n1.0\n0.9999999999999999\n1.0\n1.0\n1.0\n0.9999999999999998\n0.9999999999999998\n1.0\n0.9999999999999998\n0.9999999999999999\n1.0000000000000004\n1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(ptd[:,i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1.0000000000002123\n1.0000000000001819\n1.0000000000001932\n1.0000000000002278\n1.0000000000002331\n1.0000000000001326\n1.0000000000001597\n1.000000000000249\n1.0000000000001825\n1.0000000000001943\n1.0000000000003209\n1.0000000000001708\n1.000000000000161\n1.000000000000195\n1.000000000000146\n1.000000000000146\n1.0000000000002833\n1.0000000000001665\n1.0000000000001719\n1.0000000000001577\n1.000000000000209\n1.0000000000001965\n1.0000000000001972\n1.0000000000002218\n1.0000000000002027\n1.000000000000149\n1.000000000000151\n1.0000000000001195\n1.0000000000001688\n1.0000000000002178\n1.0000000000001923\n1.0000000000002072\n"
     ]
    }
   ],
   "source": [
    "for i in range(topic_k):\n",
    "    print(pwt[:,i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.7.4-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}